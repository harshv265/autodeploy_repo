{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Autodeployment Chat System \u2014 Colab Notebook (Aligned for Demo)\n",
        "This Colab notebook implements a **demo-ready** backend flow that:\n",
        "- Accepts **natural language** deployment instructions and a **GitHub repo URL or ZIP upload**.\n",
        "- **Analyzes** the repo to infer framework, dependencies, start commands, and port.\n",
        "- Generates an **infrastructure plan** (VM on AWS via Terraform for demo), with a dry-run option.\n",
        "- Produces and runs **Terraform** to provision an EC2 instance (Ubuntu), installs runtime, deploys the app, and exposes the service.\n",
        "- Performs a best-effort **replacement of `localhost`** with the instance's **public IP** inside common config and code files.\n",
        "- Streams **logs** for analysis and offers **destroy** to tear down infra.\n",
        "\n",
        "> Demo defaults to a single **EC2 VM** on AWS. Serverless/Kubernetes hooks are scaffolded for future work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost/"
        }
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "#@title 0) Setup & Dependencies\n",
        "# This cell installs runtime dependencies and Terraform CLI on Colab.\n",
        "# If you are running locally, make sure terraform is installed (>= 1.5).\n",
        "# You can skip re-running once installed.\n",
        "\n",
        "import os, sys, subprocess, shlex, json, re, base64, zipfile, pathlib, shutil, textwrap, glob, uuid, time\n",
        "\n",
        "def run(cmd, env=None, cwd=None, check=True):\n",
        "    print(f\"$ {cmd}\")\n",
        "    p = subprocess.run(shlex.split(cmd), env=env, cwd=cwd, capture_output=True, text=True)\n",
        "    print(p.stdout)\n",
        "    if p.returncode != 0:\n",
        "        print(p.stderr)\n",
        "        if check:\n",
        "            raise RuntimeError(f\"Command failed: {cmd}\")\n",
        "    return p\n",
        "\n",
        "# Detect if Terraform is installed; if not, attempt to install (Colab-friendly).\n",
        "def ensure_terraform():\n",
        "    try:\n",
        "        run(\"terraform version\", check=False)\n",
        "        return\n",
        "    except Exception:\n",
        "        pass\n",
        "    # Try apt-get install hashicorp repo if available; fallback to binary download otherwise.\n",
        "    try:\n",
        "        run(\"sudo apt-get update\", check=False)\n",
        "        run(\"sudo apt-get install -y gnupg software-properties-common curl unzip\", check=False)\n",
        "        run(\"curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg\", check=False)\n",
        "        run('echo \"deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(. /etc/os-release && echo $UBUNTU_CODENAME) main\" | sudo tee /etc/apt/sources.list.d/hashicorp.list', check=False)\n",
        "        run(\"sudo apt-get update\", check=False)\n",
        "        run(\"sudo apt-get install -y terraform\", check=False)\n",
        "    except Exception as e:\n",
        "        print(\"Apt path failed; trying direct download...\")\n",
        "        url = \"https://releases.hashicorp.com/terraform/1.6.6/terraform_1.6.6_linux_amd64.zip\"\n",
        "        run(f\"curl -L -o /tmp/terraform.zip {url}\", check=True)\n",
        "        run(\"unzip -o /tmp/terraform.zip -d /tmp\", check=True)\n",
        "        run(\"sudo mv /tmp/terraform /usr/local/bin/terraform\", check=True)\n",
        "        run(\"terraform version\", check=True)\n",
        "\n",
        "ensure_terraform()\n",
        "\n",
        "# Python deps\n",
        "!pip -q install gitpython ruamel.yaml tldextract >/dev/null 2>&1 || true\n",
        "\n",
        "# Workspace layout\n",
        "BASE = pathlib.Path.cwd() / \"autodeploy_workspace\"\n",
        "INFRA = BASE / \"infra\" / \"aws\" / \"vm_web\"\n",
        "REPO_DIR = BASE / \"repo\"\n",
        "LOGS = BASE / \"logs\"\n",
        "for p in [BASE, INFRA, REPO_DIR, LOGS]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Workspace:\", BASE)\n",
        "print(\"Terraform dir:\", INFRA)\n",
        "print(\"Repo dir:\", REPO_DIR)\n",
        "print(\"Logs dir:\", LOGS)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost/"
        }
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "#@title 1) Inputs \u2014 Natural Language + Repo\n",
        "# Provide deployment text and either a GitHub repo URL or upload a ZIP.\n",
        "from ipywidgets import Text, Textarea, Dropdown, BoundedIntText, Password, Checkbox, Button, HBox, VBox, FileUpload, HTML, Output\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "nlp_input = Textarea(\n",
        "    value=\"Deploy this Flask/Node app on AWS in us-east-1. Open port 3000 if needed.\",\n",
        "    placeholder=\"Natural language deployment instruction...\",\n",
        "    description=\"Instruction\",\n",
        "    layout={\"width\": \"100%\", \"height\": \"100px\"},\n",
        ")\n",
        "\n",
        "repo_url = Text(\n",
        "    value=\"https://github.com/Arvo-AI/hello_world\",\n",
        "    placeholder=\"https://github.com/user/repo or leave blank to upload ZIP\",\n",
        "    description=\"GitHub URL\",\n",
        "    layout={\"width\": \"100%\"},\n",
        ")\n",
        "\n",
        "zip_upload = FileUpload(description=\"Upload ZIP\", multiple=False)\n",
        "\n",
        "region = Dropdown(\n",
        "    options=[\n",
        "        \"us-east-1\",\"us-east-2\",\"us-west-1\",\"us-west-2\",\n",
        "        \"eu-west-1\",\"eu-central-1\",\"ap-south-1\",\"ap-southeast-1\",\"ap-southeast-2\"\n",
        "    ],\n",
        "    value=\"us-east-1\",\n",
        "    description=\"AWS Region\",\n",
        ")\n",
        "\n",
        "instance_type = Text(value=\"t3.micro\", description=\"Instance\")\n",
        "open_port = BoundedIntText(value=3000, min=1, max=65535, description=\"Open Port\")\n",
        "allow_http = Checkbox(value=True, description=\"Open port 80 (HTTP)\")\n",
        "dry_run = Checkbox(value=False, description=\"Dry Run (no apply)\")\n",
        "\n",
        "aws_key_id = Text(value=\"\", description=\"AWS_KEY_ID\")\n",
        "aws_secret = Password(value=\"\", description=\"AWS_SECRET\")\n",
        "aws_session = Text(value=\"\", description=\"AWS_SESSION\")  # Optional\n",
        "\n",
        "analyze_btn = Button(description=\"Analyze Repo\", button_style=\"info\")\n",
        "plan_btn = Button(description=\"Generate Plan\", button_style=\"warning\")\n",
        "apply_btn = Button(description=\"Provision & Deploy\", button_style=\"success\")\n",
        "destroy_btn = Button(description=\"Destroy Infra\", button_style=\"danger\")\n",
        "\n",
        "status = Output()\n",
        "\n",
        "def save_zip_to_repo(upload_widget):\n",
        "    REPO_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    # Clear repo dir\n",
        "    for p in REPO_DIR.glob(\"*\"):\n",
        "        if p.is_file():\n",
        "            p.unlink()\n",
        "        else:\n",
        "            shutil.rmtree(p, ignore_errors=True)\n",
        "    if upload_widget.value:\n",
        "        (_fname, fileinfo), = upload_widget.value.items()\n",
        "        content = fileinfo[\"content\"]\n",
        "        zpath = BASE / \"uploaded.zip\"\n",
        "        with open(zpath, \"wb\") as f:\n",
        "            f.write(content)\n",
        "        with zipfile.ZipFile(zpath, 'r') as zip_ref:\n",
        "            zip_ref.extractall(REPO_DIR)\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def clone_repo(url):\n",
        "    # Clean repo dir\n",
        "    for p in REPO_DIR.glob(\"*\"):\n",
        "        if p.is_file():\n",
        "            p.unlink()\n",
        "        else:\n",
        "            shutil.rmtree(p, ignore_errors=True)\n",
        "    if not url.strip():\n",
        "        return False\n",
        "    run(f\"git clone --depth=1 {shlex.quote(url)} {shlex.quote(str(REPO_DIR))}\", check=True)\n",
        "    return True\n",
        "\n",
        "import re, pathlib, json\n",
        "\n",
        "def detect_app(repo_path):\n",
        "    \"\"\"Heuristic analysis of repo to infer application details.\"\"\"\n",
        "    out = {\n",
        "        \"framework\": None, \"language\": None, \"start_cmd\": None, \"port\": None,\n",
        "        \"env\": {}, \"notes\": [], \"has_dockerfile\": False\n",
        "    }\n",
        "    rp = pathlib.Path(repo_path)\n",
        "\n",
        "    # Dockerfile?\n",
        "    if (rp / \"Dockerfile\").exists():\n",
        "        out[\"has_dockerfile\"] = True\n",
        "        out[\"notes\"].append(\"Dockerfile found.\")\n",
        "\n",
        "    # Node.js detection\n",
        "    pkg = rp / \"package.json\"\n",
        "    if pkg.exists():\n",
        "        out[\"language\"] = \"node\"\n",
        "        out[\"framework\"] = \"node\"\n",
        "        try:\n",
        "            data = json.loads(pkg.read_text())\n",
        "            scripts = (data.get(\"scripts\") or {})\n",
        "            # Prefer 'start' if present\n",
        "            if \"start\" in scripts:\n",
        "                out[\"start_cmd\"] = \"npm start\"\n",
        "            elif \"serve\" in scripts:\n",
        "                out[\"start_cmd\"] = \"npm run serve\"\n",
        "            else:\n",
        "                out[\"start_cmd\"] = \"node index.js\"\n",
        "            # try to infer port\n",
        "            # common patterns: process.env.PORT || 3000 etc.\n",
        "            for path in rp.rglob(\"*.js\"):\n",
        "                text = path.read_text(errors=\"ignore\")\n",
        "                m = re.search(r\"(?:PORT|port)\\D{0,3}(\\d{2,5})\", text)\n",
        "                if m:\n",
        "                    out[\"port\"] = int(m.group(1)); break\n",
        "            if out[\"port\"] is None:\n",
        "                out[\"port\"] = 3000\n",
        "            return out\n",
        "        except Exception as e:\n",
        "            out[\"notes\"].append(f\"package.json parse failed: {e}\")\n",
        "\n",
        "    # Python detection (Flask, Django, FastAPI)\n",
        "    req = rp / \"requirements.txt\"\n",
        "    pyproject = rp / \"pyproject.toml\"\n",
        "    pipfile = rp / \"Pipfile\"\n",
        "    found_py = any([req.exists(), pyproject.exists(), pipfile.exists(), list(rp.rglob(\"*.py\"))])\n",
        "    if found_py:\n",
        "        out[\"language\"] = \"python\"\n",
        "        requirements = (req.read_text(errors=\"ignore\").lower() if req.exists() else \"\")\n",
        "        code_blobs = []\n",
        "        for p in rp.rglob(\"*.py\"):\n",
        "            try:\n",
        "                code_blobs.append(p.read_text(errors=\"ignore\").lower())\n",
        "            except Exception:\n",
        "                pass\n",
        "        code_all = \"\\n\".join(code_blobs)\n",
        "\n",
        "        if \"flask\" in requirements or \"from flask\" in code_all:\n",
        "            out[\"framework\"] = \"flask\"\n",
        "            out[\"start_cmd\"] = \"gunicorn app:app --bind 0.0.0.0:$PORT\"\n",
        "            out[\"port\"] = 5000\n",
        "        elif \"fastapi\" in requirements or \"from fastapi\" in code_all:\n",
        "            out[\"framework\"] = \"fastapi\"\n",
        "            out[\"start_cmd\"] = \"uvicorn app:app --host 0.0.0.0 --port $PORT\"\n",
        "            out[\"port\"] = 8000\n",
        "        elif \"django\" in requirements or \"import django\" in code_all:\n",
        "            out[\"framework\"] = \"django\"\n",
        "            out[\"start_cmd\"] = \"gunicorn mysite.wsgi:application --bind 0.0.0.0:$PORT\"\n",
        "            out[\"port\"] = 8000\n",
        "        else:\n",
        "            out[\"framework\"] = \"python_app\"\n",
        "            out[\"start_cmd\"] = \"python3 app.py\"\n",
        "            out[\"port\"] = 8000\n",
        "\n",
        "        # Try to find explicit port in code (e.g., app.run(..., port=1234))\n",
        "        m = re.search(r\"port\\s*=\\s*(\\d{2,5})\", code_all)\n",
        "        if m:\n",
        "            out[\"port\"] = int(m.group(1))\n",
        "        return out\n",
        "\n",
        "    # Default fallback\n",
        "    out[\"framework\"] = \"unknown\"\n",
        "    out[\"language\"] = \"unknown\"\n",
        "    out[\"start_cmd\"] = None\n",
        "    out[\"port\"] = 8080\n",
        "    out[\"notes\"].append(\"Could not detect framework; defaulting to port 8080.\")\n",
        "    return out\n",
        "\n",
        "analysis = {}\n",
        "tfvars = {}\n",
        "\n",
        "def on_analyze(_):\n",
        "    with status:\n",
        "        clear_output()\n",
        "        print(\"== Analyzing input ==\")\n",
        "    ok = False\n",
        "    if repo_url.value.strip():\n",
        "        ok = clone_repo(repo_url.value.strip())\n",
        "    else:\n",
        "        ok = save_zip_to_repo(zip_upload)\n",
        "    if not ok:\n",
        "        with status:\n",
        "            print(\"No repository provided. Please supply a GitHub URL or upload a ZIP.\")\n",
        "        return\n",
        "    global analysis\n",
        "    analysis = detect_app(REPO_DIR)\n",
        "    analysis[\"region\"] = region.value\n",
        "    analysis[\"open_port\"] = open_port.value\n",
        "    analysis[\"allow_http\"] = bool(allow_http.value)\n",
        "    with status:\n",
        "        print(\"Analysis:\", json.dumps(analysis, indent=2))\n",
        "\n",
        "def on_generate_plan(_):\n",
        "    if not analysis:\n",
        "        with status:\n",
        "            print(\"Run Analyze first.\")\n",
        "        return\n",
        "    # Decision policy: always VM for demo; scaffold others\n",
        "    plan = {\n",
        "        \"strategy\": \"vm_ec2\",\n",
        "        \"region\": analysis[\"region\"],\n",
        "        \"instance_type\": instance_type.value.strip() or \"t3.micro\",\n",
        "        \"open_ports\": list({analysis[\"open_port\"], 80} if allow_http.value else {analysis[\"open_port\"]}),\n",
        "        \"language\": analysis[\"language\"],\n",
        "        \"framework\": analysis[\"framework\"],\n",
        "        \"port\": analysis[\"open_port\"] or analysis[\"port\"] or 8080,\n",
        "        \"start_cmd\": analysis[\"start_cmd\"],\n",
        "        \"repo_url\": repo_url.value.strip() if repo_url.value.strip() else \"uploaded_zip\",\n",
        "    }\n",
        "    global tfvars\n",
        "    tfvars = plan\n",
        "    with status:\n",
        "        clear_output()\n",
        "        print(\"== Deployment plan ==\")\n",
        "        print(json.dumps(plan, indent=2))\n",
        "        print(\"\\nNext: click 'Provision & Deploy' to create infra (or enable Dry Run).\")\n",
        "\n",
        "def write_file(path, content):\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(path, \"w\", newline=\"\\n\") as f:\n",
        "        f.write(content)\n",
        "\n",
        "def generate_terraform(plan):\n",
        "    import uuid\n",
        "    app_name = f\"autodeploy-{uuid.uuid4().hex[:8]}\"\n",
        "    port = plan[\"port\"]\n",
        "    open_ports = plan[\"open_ports\"]\n",
        "    region = plan[\"region\"]\n",
        "    instance_type = plan[\"instance_type\"]\n",
        "    repo = plan[\"repo_url\"]\n",
        "    start_cmd = plan[\"start_cmd\"] or \"\"\n",
        "\n",
        "    variables_tf = f\"\"\"\n",
        "variable \"app_name\" {{\n",
        "  type = string\n",
        "  default = \"{app_name}\"\n",
        "}}\n",
        "\n",
        "variable \"instance_type\" {{\n",
        "  type    = string\n",
        "  default = \"{instance_type}\"\n",
        "}}\n",
        "\n",
        "variable \"region\" {{\n",
        "  type    = string\n",
        "  default = \"{region}\"\n",
        "}}\n",
        "\n",
        "variable \"open_ports\" {{\n",
        "  type    = list(number)\n",
        "  default = [{\", \".join(map(str, open_ports))}]\n",
        "}}\n",
        "\n",
        "variable \"app_port\" {{\n",
        "  type    = number\n",
        "  default = {port}\n",
        "}}\n",
        "\n",
        "variable \"repo_url\" {{\n",
        "  type    = string\n",
        "  default = \"{repo}\"\n",
        "}}\n",
        "\n",
        "variable \"start_cmd\" {{\n",
        "  type    = string\n",
        "  default = \"{start_cmd}\"\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "    main_tf = r\"\"\"\n",
        "terraform {\n",
        "  required_providers {\n",
        "    aws = {\n",
        "      source  = \"hashicorp/aws\"\n",
        "      version = \"~> 5.0\"\n",
        "    }\n",
        "  }\n",
        "  required_version = \">= 1.5.0\"\n",
        "}\n",
        "\n",
        "provider \"aws\" {\n",
        "  region = var.region\n",
        "}\n",
        "\n",
        "data \"aws_ami\" \"ubuntu\" {\n",
        "  most_recent = true\n",
        "  owners      = [\"099720109477\"]\n",
        "  filter {\n",
        "    name   = \"name\"\n",
        "    values = [\"ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-amd64-server-*\"]\n",
        "  }\n",
        "}\n",
        "\n",
        "resource \"aws_security_group\" \"app_sg\" {\n",
        "  name        = \"${var.app_name}-sg\"\n",
        "  description = \"Security group for ${var.app_name}\"\n",
        "\n",
        "  dynamic \"ingress\" {\n",
        "    for_each = var.open_ports\n",
        "    content {\n",
        "      description = \"App port\"\n",
        "      from_port   = ingress.value\n",
        "      to_port     = ingress.value\n",
        "      protocol    = \"tcp\"\n",
        "      cidr_blocks = [\"0.0.0.0/0\"]\n",
        "      ipv6_cidr_blocks = [\"::/0\"]\n",
        "    }\n",
        "  }\n",
        "\n",
        "  egress {\n",
        "    from_port   = 0\n",
        "    to_port     = 0\n",
        "    protocol    = \"-1\"\n",
        "    cidr_blocks = [\"0.0.0.0/0\"]\n",
        "    ipv6_cidr_blocks = [\"::/0\"]\n",
        "  }\n",
        "}\n",
        "\n",
        "resource \"aws_instance\" \"app\" {\n",
        "  ami                         = data.aws_ami.ubuntu.id\n",
        "  instance_type               = var.instance_type\n",
        "  associate_public_ip_address = true\n",
        "  vpc_security_group_ids      = [aws_security_group.app_sg.id]\n",
        "\n",
        "  user_data = templatefile(\"${path.module}/user_data.sh.tftpl\", {\n",
        "    REPO_URL  = var.repo_url,\n",
        "    APP_PORT  = var.app_port,\n",
        "    START_CMD = var.start_cmd\n",
        "  })\n",
        "\n",
        "  tags = {\n",
        "    Name = var.app_name\n",
        "  }\n",
        "}\n",
        "\n",
        "output \"public_ip\" {\n",
        "  value = aws_instance.app.public_ip\n",
        "}\n",
        "\n",
        "output \"public_dns\" {\n",
        "  value = aws_instance.app.public_dns\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "    user_data_tpl = r\"\"\"\n",
        "#!/bin/bash\n",
        "set -euxo pipefail\n",
        "\n",
        "export DEBIAN_FRONTEND=noninteractive\n",
        "apt-get update -y\n",
        "apt-get install -y curl git jq unzip python3-pip python3-venv\n",
        "\n",
        "# Install Node (LTS) from Nodesource\n",
        "curl -fsSL https://deb.nodesource.com/setup_18.x | bash -\n",
        "apt-get install -y nodejs\n",
        "\n",
        "# Discover public IP for localhost replacement\n",
        "PUBIP=$(curl -s http://169.254.169.254/latest/meta-data/public-ipv4 || echo \"127.0.0.1\")\n",
        "\n",
        "# Create app folder\n",
        "mkdir -p /opt/app\n",
        "cd /opt/app\n",
        "\n",
        "# Fetch repo\n",
        "git clone --depth=1 \"${REPO_URL}\" app || true\n",
        "cd app\n",
        "\n",
        "# Replace localhost with public IP in common text files\n",
        "grep -rIl \"localhost\" . | xargs -r sed -i \"s/localhost/${PUBIP}/g\" || true\n",
        "\n",
        "# Try Node first\n",
        "if [ -f package.json ]; then\n",
        "  npm install --omit=dev || npm install\n",
        "  APPSTART=\"${START_CMD:-npm start}\"\n",
        "  if ! grep -q '\"start\"' package.json; then\n",
        "    APPSTART=\"node index.js\"\n",
        "  fi\n",
        "  RUNTIME=\"node\"\n",
        "else\n",
        "  # Python path\n",
        "  python3 -m venv .venv\n",
        "  . .venv/bin/activate\n",
        "  if [ -f requirements.txt ]; then pip install -r requirements.txt || true; fi\n",
        "  if [ -f pyproject.toml ]; then pip install . || true; fi\n",
        "  APPSTART=\"${START_CMD:-gunicorn app:app --bind 0.0.0.0:${APP_PORT}}\"\n",
        "  RUNTIME=\"python\"\n",
        "fi\n",
        "\n",
        "# Create systemd service\n",
        "cat >/etc/systemd/system/app.service <<EOF\n",
        "[Unit]\n",
        "Description=Autodeploy App\n",
        "After=network.target\n",
        "\n",
        "[Service]\n",
        "WorkingDirectory=/opt/app/app\n",
        "ExecStart=/bin/bash -lc 'PORT=${APP_PORT} ${APPSTART}'\n",
        "Restart=always\n",
        "Environment=PORT=${APP_PORT}\n",
        "Environment=HOST=0.0.0.0\n",
        "User=root\n",
        "\n",
        "[Install]\n",
        "WantedBy=multi-user.target\n",
        "EOF\n",
        "\n",
        "systemctl daemon-reload\n",
        "systemctl enable app.service\n",
        "systemctl restart app.service\n",
        "\"\"\"\n",
        "\n",
        "    outputs_tf = r\"\"\"\n",
        "output \"app_url_http\" {\n",
        "  value = \"http://${aws_instance.app.public_ip}:${var.app_port}\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "    write_file(INFRA / \"variables.tf\", variables_tf)\n",
        "    write_file(INFRA / \"main.tf\", main_tf)\n",
        "    write_file(INFRA / \"outputs.tf\", outputs_tf)\n",
        "    write_file(INFRA / \"user_data.sh.tftpl\", user_data_tpl)\n",
        "\n",
        "def on_apply(_):\n",
        "    if not tfvars:\n",
        "        with status:\n",
        "            print(\"Generate Plan first.\")\n",
        "        return\n",
        "\n",
        "    generate_terraform(tfvars)\n",
        "\n",
        "    env = os.environ.copy()\n",
        "    if aws_key_id.value and aws_secret.value:\n",
        "        env[\"AWS_ACCESS_KEY_ID\"] = aws_key_id.value\n",
        "        env[\"AWS_SECRET_ACCESS_KEY\"] = aws_secret.value\n",
        "        if aws_session.value:\n",
        "            env[\"AWS_SESSION_TOKEN\"] = aws_session.value\n",
        "    else:\n",
        "        with status:\n",
        "            print(\"Warning: No AWS credentials supplied in widgets. If your environment already has credentials, that's fine.\")\n",
        "\n",
        "    # Terraform workflow\n",
        "    try:\n",
        "        run(\"terraform -chdir=%s init\" % str(INFRA), env=env, check=True)\n",
        "        run(\"terraform -chdir=%s validate\" % str(INFRA), env=env, check=False)\n",
        "        plan_out = LOGS / \"plan.out\"\n",
        "        run(f\"terraform -chdir={str(INFRA)} plan -out={str(plan_out)}\", env=env, check=True)\n",
        "        if dry_run.value:\n",
        "            with status:\n",
        "                print(\"Dry run enabled \u2014 not applying.\")\n",
        "            return\n",
        "        run(f\"terraform -chdir={str(INFRA)} apply -auto-approve {str(plan_out)}\", env=env, check=True)\n",
        "        # Show outputs\n",
        "        p = run(f\"terraform -chdir={str(INFRA)} output -json\", env=env, check=True)\n",
        "        try:\n",
        "            outs = json.loads(p.stdout)\n",
        "            with status:\n",
        "                print(\"== Outputs ==\")\n",
        "                print(json.dumps(outs, indent=2))\n",
        "        except Exception:\n",
        "            pass\n",
        "    except Exception as e:\n",
        "        with status:\n",
        "            print(\"Provisioning failed:\", e)\n",
        "\n",
        "def on_destroy(_):\n",
        "    env = os.environ.copy()\n",
        "    if aws_key_id.value and aws_secret.value:\n",
        "        env[\"AWS_ACCESS_KEY_ID\"] = aws_key_id.value\n",
        "        env[\"AWS_SECRET_ACCESS_KEY\"] = aws_secret.value\n",
        "        if aws_session.value:\n",
        "            env[\"AWS_SESSION_TOKEN\"] = aws_session.value\n",
        "    try:\n",
        "        run(f\"terraform -chdir={str(INFRA)} destroy -auto-approve\", env=env, check=False)\n",
        "    finally:\n",
        "        with status:\n",
        "            print(\"Destroy attempted; check logs above for details.\")\n",
        "\n",
        "analyze_btn.on_click(on_analyze)\n",
        "plan_btn.on_click(on_generate_plan)\n",
        "apply_btn.on_click(on_apply)\n",
        "destroy_btn.on_click(on_destroy)\n",
        "\n",
        "display(\n",
        "    VBox([\n",
        "        nlp_input,\n",
        "        repo_url,\n",
        "        zip_upload,\n",
        "        HBox([region, instance_type, open_port, allow_http]),\n",
        "        HBox([dry_run]),\n",
        "        HTML(\"<b>AWS Credentials (optional here if your Colab has them already)</b>\"),\n",
        "        HBox([aws_key_id, aws_secret, aws_session]),\n",
        "        HBox([analyze_btn, plan_btn, apply_btn, destroy_btn]),\n",
        "        status,\n",
        "    ])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes & Policy Alignment (for Demo)\n",
        "- **Terraform** is the provisioning backbone (VM on AWS).  \n",
        "- **Minimal intervention**: one-click Analyze \u2192 Plan \u2192 Provision.  \n",
        "- **Generality**: Heuristics support **Node**, **Flask/Django/FastAPI**, and a fallback Python app.  \n",
        "- **Adjustments**: Attempts to replace `localhost` with the instance **public IP** and binds to `0.0.0.0`.  \n",
        "- **Logs**: Terraform logs and outputs are printed inline; systemd manages the app lifecycle.  \n",
        "- **Future hooks**: Stubs allow extending to serverless (Lambda/API GW) or containers (ECS/EKS).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### How to Demo Quickly\n",
        "1. Click **Analyze Repo** with `https://github.com/Arvo-AI/hello_world` or upload a ZIP.  \n",
        "2. Click **Generate Plan** and review inferred framework/port.  \n",
        "3. Supply AWS creds (or rely on attached Colab secrets), then click **Provision & Deploy**.  \n",
        "4. When done, click **Destroy Infra**.\n",
        "\n",
        "> If you lack AWS creds, enable **Dry Run** to show the full plan without applying."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Autodeploy_Colab_v3_fixed.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    },
    "authors": [
      {
        "name": "ChatGPT"
      },
      {
        "name": "User"
      }
    ],
    "created": "2025-09-06T04:49:01.368757Z"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}